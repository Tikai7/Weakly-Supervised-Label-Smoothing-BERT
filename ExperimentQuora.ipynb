{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model.Train import Trainer\n",
    "from model.Loss import LSmoothing, WSLSmoothing\n",
    "from torch.utils.data import DataLoader\n",
    "from model.Bert import BertForQuestionPairClassification\n",
    "from model.DataManager import QuoraDataset\n",
    "from transformers import BertTokenizer\n",
    "from model.NegativeSampling import RandomSampling, BM25Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "path =\"data/quora-question-pairs/train.csv\"\n",
    "bs = 32\n",
    "bm25_sampling = True\n",
    "\n",
    "data = QuoraDataset.load_data(path, 1000)\n",
    "data['global_docno'] = data.index.astype(str)\n",
    "train_data, val_data, test_data = QuoraDataset.split_data(data)\n",
    "if bm25_sampling : \n",
    "    index_ref_tr = QuoraDataset.index_data(train_data,type_df=\"train_5\")\n",
    "    index_ref_val = QuoraDataset.index_data(val_data,type_df=\"val_5\")\n",
    "    index_ref_test = QuoraDataset.index_data(test_data,type_df=\"test_5\")\n",
    "    train_data = BM25Sampling.sample(index_ref_tr,train_data, k=9).sort_values(by=\"question1\")\n",
    "    val_data = BM25Sampling.sample(index_ref_val,val_data, k=9).sort_values(by=\"question1\")\n",
    "    test_data = BM25Sampling.sample(index_ref_test,test_data, k=9).sort_values(by=\"question1\")\n",
    "else:\n",
    "    train_data = RandomSampling.sample(train_data, k=9).sort_values(by=\"question1\")\n",
    "    val_data = RandomSampling.sample(val_data, k=9).sort_values(by=\"question1\")\n",
    "    test_data = RandomSampling.sample(test_data, k=9).sort_values(by=\"question1\")\n",
    "\n",
    "train_dataset = QuoraDataset(train_data, tokenizer, max_length=128)\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "val_dataset = QuoraDataset(val_data, tokenizer, max_length=128)\n",
    "val_loader = DataLoader(val_dataset, batch_size=10, shuffle=False)\n",
    "test_dataset = QuoraDataset(test_data, tokenizer, max_length=128)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "epochs = 10\n",
    "learning_rate = 1e-4\n",
    "\n",
    "model = BertForQuestionPairClassification()\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW\n",
    "loss = LSmoothing()\n",
    "trainer = Trainer()\n",
    "history = trainer.set_model(model)\\\n",
    "    .set_loader(train_loader, val_loader, None)\\\n",
    "    .set_loss_fn(loss)\\\n",
    "    .set_optimizer(optimizer)\\\n",
    "    .fit(learning_rate, epochs, CL=False)\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history['training']['loss']\n",
    "val_loss = history['validation']['loss']\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(train_loss, label='train loss')\n",
    "plt.plot(val_loss, label='val loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(all_scores, all_targets, K, num_duplicate):\n",
    "    top_k_indices = np.argsort(all_scores)[::-1][:K]\n",
    "    top_k_targets = all_targets[top_k_indices]\n",
    "    # Calculate recall\n",
    "    recall = np.sum(top_k_targets) / num_duplicate\n",
    "    return recall\n",
    "\n",
    "def evaluate_ranking_model(model, data_loader, K, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    recalls = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, ns_scores in data_loader:\n",
    "            # Move all inputs to the correct device\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "            ns_scores = ns_scores.to(device)\n",
    "            outputs = model(**inputs)\n",
    "            scores = torch.softmax(outputs, dim=1)[:, 1]  # Probability of being similar\n",
    "            scores = scores.cpu().numpy()\n",
    "            targets = labels.cpu().numpy()\n",
    "            # Assume all entries in a batch belong to one group/query\n",
    "            num_duplicate = np.sum(targets)  # Count of relevant documents/questions\n",
    "            if num_duplicate == 0:\n",
    "                continue  # Avoid division by zero\n",
    "            recall_k = recall_at_k(scores, targets, K, num_duplicate)\n",
    "            recalls.append(recall_k)\n",
    "\n",
    "    # Average over all queries\n",
    "    avg_recall = np.mean(recalls)\n",
    "    return {\n",
    "        f\"recall_at_{K}\": avg_recall\n",
    "    }\n",
    "\n",
    "metrics = evaluate_ranking_model(model, test_loader, K=1, device=device)\n",
    "print(\"Ranking Metrics:\", metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
