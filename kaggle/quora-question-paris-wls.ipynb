{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1423,"sourceType":"datasetVersion","datasetId":747}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pyterrier as pt\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom transformers import BertModel\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-21T16:58:46.992485Z","iopub.execute_input":"2024-05-21T16:58:46.992876Z","iopub.status.idle":"2024-05-21T16:58:47.053009Z","shell.execute_reply.started":"2024-05-21T16:58:46.992847Z","shell.execute_reply":"2024-05-21T16:58:47.051937Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install python-terrier\n!apt-get install java","metadata":{"execution":{"iopub.status.busy":"2024-05-21T16:58:47.054640Z","iopub.execute_input":"2024-05-21T16:58:47.055176Z","iopub.status.idle":"2024-05-21T16:59:03.127128Z","shell.execute_reply.started":"2024-05-21T16:58:47.055145Z","shell.execute_reply":"2024-05-21T16:59:03.126158Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: python-terrier in /opt/conda/lib/python3.10/site-packages (0.10.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from python-terrier) (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from python-terrier) (2.1.4)\nRequirement already satisfied: wget in /opt/conda/lib/python3.10/site-packages (from python-terrier) (3.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from python-terrier) (4.66.1)\nRequirement already satisfied: pyjnius>=1.4.2 in /opt/conda/lib/python3.10/site-packages (from python-terrier) (1.6.1)\nRequirement already satisfied: matchpy in /opt/conda/lib/python3.10/site-packages (from python-terrier) (0.5.5)\nRequirement already satisfied: deprecated in /opt/conda/lib/python3.10/site-packages (from python-terrier) (1.2.14)\nRequirement already satisfied: chest in /opt/conda/lib/python3.10/site-packages (from python-terrier) (0.2.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from python-terrier) (1.11.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from python-terrier) (2.31.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from python-terrier) (1.4.0)\nRequirement already satisfied: nptyping==1.4.4 in /opt/conda/lib/python3.10/site-packages (from python-terrier) (1.4.4)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from python-terrier) (10.2.0)\nRequirement already satisfied: ir-datasets>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from python-terrier) (0.5.7)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from python-terrier) (3.1.2)\nRequirement already satisfied: statsmodels in /opt/conda/lib/python3.10/site-packages (from python-terrier) (0.14.1)\nRequirement already satisfied: ir-measures>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from python-terrier) (0.3.3)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from python-terrier) (0.3.8)\nRequirement already satisfied: pytrec-eval-terrier>=0.5.3 in /opt/conda/lib/python3.10/site-packages (from python-terrier) (0.5.6)\nRequirement already satisfied: typish>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from nptyping==1.4.4->python-terrier) (1.9.3)\nRequirement already satisfied: beautifulsoup4>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.12.2)\nRequirement already satisfied: inscriptis>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (2.5.0)\nRequirement already satisfied: lxml>=4.5.2 in /opt/conda/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (5.2.1)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (6.0.1)\nRequirement already satisfied: trec-car-tools>=2.5.4 in /opt/conda/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (2.6)\nRequirement already satisfied: lz4>=3.1.10 in /opt/conda/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.3.3)\nRequirement already satisfied: warc3-wet>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.3)\nRequirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /opt/conda/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.5)\nRequirement already satisfied: zlib-state>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.6)\nRequirement already satisfied: ijson>=3.1.3 in /opt/conda/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (3.2.3)\nRequirement already satisfied: unlzw3>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.2)\nRequirement already satisfied: cwl-eval>=1.0.10 in /opt/conda/lib/python3.10/site-packages (from ir-measures>=0.3.1->python-terrier) (1.0.12)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->python-terrier) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->python-terrier) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->python-terrier) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->python-terrier) (2024.2.2)\nRequirement already satisfied: heapdict in /opt/conda/lib/python3.10/site-packages (from chest->python-terrier) (1.0.1)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated->python-terrier) (1.14.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->python-terrier) (2.1.3)\nRequirement already satisfied: multiset<3.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from matchpy->python-terrier) (2.1.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->python-terrier) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->python-terrier) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->python-terrier) (2023.4)\nRequirement already satisfied: patsy>=0.5.4 in /opt/conda/lib/python3.10/site-packages (from statsmodels->python-terrier) (0.5.6)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels->python-terrier) (21.3)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier) (2.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.3->statsmodels->python-terrier) (3.1.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.4->statsmodels->python-terrier) (1.16.0)\nRequirement already satisfied: cbor>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier) (1.0.0)\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nE: Unable to locate package java\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls -la /usr/lib/jvm/java-11-openjdk-amd64\nimport os\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"","metadata":{"execution":{"iopub.status.busy":"2024-05-21T16:59:03.128643Z","iopub.execute_input":"2024-05-21T16:59:03.129011Z","iopub.status.idle":"2024-05-21T16:59:04.118942Z","shell.execute_reply.started":"2024-05-21T16:59:03.128977Z","shell.execute_reply":"2024-05-21T16:59:04.117858Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"total 32\ndrwxr-xr-x  7 root root 4096 Apr 17 20:25 .\ndrwxr-xr-x  3 root root 4096 Apr 17 20:25 ..\ndrwxr-xr-x  2 root root 4096 Apr 17 20:25 bin\ndrwxr-xr-x  4 root root 4096 Apr 17 20:25 conf\nlrwxrwxrwx  1 root root   42 Jan 20 10:27 docs -> ../../../share/doc/openjdk-11-jre-headless\ndrwxr-xr-x 73 root root 4096 Apr 17 20:25 legal\ndrwxr-xr-x  6 root root 4096 Apr 17 20:25 lib\ndrwxr-xr-x  4 root root 4096 Apr 17 20:25 man\n-rw-r--r--  1 root root 1250 Jan 20 10:27 release\n","output_type":"stream"}]},{"cell_type":"code","source":"if not pt.started():\n   pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])\npd.set_option('display.max_colwidth', 150)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T16:59:04.122108Z","iopub.execute_input":"2024-05-21T16:59:04.122547Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"terrier-assemblies 5.9 jar-with-dependencies not found, downloading to /root/.pyterrier...\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\ndef load_data(path,size=None):\n    data = pd.read_csv(path)\n    # Assuming the dataset columns are ['qid1', 'qid2', 'question1', 'question2', 'is_duplicate']\n    data = data.dropna()  # Removing rows with null values\n    data = data[data['is_duplicate'] == 1]\n    data = data.sample(size) if size else data\n    data.drop(columns=data.columns[:3],inplace=True)\n    return data\n\ndef split_data(data, test_size=0.1, val_size=0.1):\n    train_val, test = train_test_split(data, test_size=test_size, random_state=42)\n    train, val = train_test_split(train_val, test_size=val_size/(1-test_size), random_state=42)\n    return train, val, test\n    \ndef index_data(df, type_df=\"train\"):\n    indexer = pt.DFIndexer(\"./index_\" + type_df, overwrite=True)\n    data_to_index = df.copy()\n    data_to_index['docno'] = data_to_index['global_docno']\n    index_ref = indexer.index(data_to_index['question1'], data_to_index['question2'], data_to_index['docno'])\n    return index_ref\n    \ndef tokenize_questions(question1, question2, max_length=128):\n    return tokenizer(question1, question2, padding='max_length', max_length=max_length, truncation=True, return_tensors='pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport torch\n\nclass QuoraDataset(Dataset):\n    def __init__(self, data, tokenizer, max_length):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        inputs = self.tokenizer(row['question1'], row['question2'],\n                                padding='max_length', max_length=self.max_length, truncation=True)\n        inputs = {key: torch.tensor(val) for key, val in inputs.items()}\n        label = torch.tensor(row['is_duplicate'])\n        score = torch.tensor(row['score'], dtype=torch.float)\n        return inputs, label, score\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RandomSampling():\n    @staticmethod\n    def sample(data, k=2):\n        data['random_score'] = np.random.uniform(0, 1, size=len(data))\n        duplicates = data[data['is_duplicate'] == 1]\n        new_question1 = []\n        new_question2 = []\n        new_labels = []\n        random_scores = []\n        for _, row in duplicates.iterrows():\n            sampled_rows = duplicates.sample(n=k, replace=False)  # replace=True to allow choosing the same row more than once if needed\n            for _, other_row in sampled_rows.iterrows():\n                if row['question1'] != other_row['question1']:  # Ensure not to duplicate the exact pair\n                    new_question1.append(row['question1'])\n                    new_question2.append(other_row['question2'])\n                    new_labels.append(0)  # These are non-duplicate by design\n                    random_scores.append(np.random.uniform(0, 1))\n        augmented_data = pd.DataFrame({\n            'question1': new_question1,\n            'question2': new_question2,\n            'is_duplicate': new_labels,\n            'score': random_scores\n        })\n        final_df = pd.concat([data, augmented_data], ignore_index=True)\n        # Drop the 'global_docno' column before returning\n        final_df = final_df.drop(columns=random_score)\n        return final_df\n    \n\nclass BM25Sampling():\n    @staticmethod\n    def preprocess_query(query):\n        # Basic preprocessing to ensure consistent query formatting\n        query = query.lower()\n        query = re.sub(r'[^\\w\\s]', '', query)  # Remove punctuation\n        return query\n    \n    @staticmethod\n    def sample(index_ref, data, k=2):\n        index = pt.IndexFactory.of(index_ref)\n        bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\", metadata=['docno'])\n        \n        new_questions = []\n        # Iterate through each row in the dataset that are duplicates\n        duplicates = data[data['is_duplicate'] == 1]\n        for _, row in duplicates.iterrows():\n            # Prepare the query from question1\n            query_df = pd.DataFrame({'query': [BM25Sampling.preprocess_query(row['question1'])], 'qid': [1]})\n            results = bm25.transform(query_df)\n            # Get top k results, excluding the current question itself\n            valid_results = results[results['docno'].isin(data['global_docno']) & (results['docno'] != row['global_docno'])].head(k)\n            for _, result in valid_results.iterrows():\n                matched_row = data[data['global_docno'] == result['docno']].iloc[0]\n                new_questions.append({\n                    'question1': row['question1'],\n                    'question2': matched_row['question2'],\n                    'is_duplicate': 0,\n                    'score': result['score'] if pd.notna(result['score']) else np.random.uniform()\n                })\n        # Create a DataFrame from the collected new questions\n        augmented_data = pd.DataFrame(new_questions)\n\n        # Combine with the original data\n        final_df = pd.concat([data, augmented_data], ignore_index=True)\n        # Normalize scores if present and handle NaN\n        if 'score' in final_df:\n            final_df['score'].fillna(final_df.apply(lambda x: np.random.uniform() if x['is_duplicate'] == 0 else 1, axis=1), inplace=True)\n            max_score = final_df['score'].max()\n            min_score = final_df['score'].min()\n            if max_score > min_score:  # Prevent division by zero\n                final_df['score'] = (final_df['score'] - min_score) / (max_score - min_score)\n            else:\n                final_df['score'] = 0.0  # If all scores are the same\n\n        # Drop the 'global_docno' column before returning\n        final_df = final_df.drop(columns=\"global_docno\")\n        return final_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass BertForQuestionPairClassification(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.classifier = nn.Linear(self.bert.config.hidden_size, 2)\n        self.dropout = nn.Dropout(0.1)\n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        pooled_output = self.dropout(outputs.pooler_output)\n        logits = self.classifier(pooled_output)\n        return logits\n\nclass LSmoothing(nn.Module):\n    def __init__(self, epsilon=0.1, num_classes=2):\n        super().__init__()\n        self.num_classes = num_classes\n    def forward(self, outputs, targets, ns_scores=None, epsilon=0.1, return_sl=False):\n        # Create a tensor to hold the smoothed labels\n        batch_size = targets.size(0)  # Number of examples in the batch\n        smoothed_labels = torch.full((batch_size, self.num_classes), epsilon / (self.num_classes - 1), device=outputs.device)\n        # Create a zero tensor the same size as smoothed_labels for one-hot encoding\n        targets_one_hot = torch.zeros_like(smoothed_labels)  # Ensure device matches\n        # Scatter 1s into the correct indices in targets_one_hot\n        targets_one_hot.scatter_(1, targets.unsqueeze(1), 1.0)  # No device argument here\n        # Combine the uniform and one-hot distributions\n        smoothed_labels = (1 - epsilon) * targets_one_hot + epsilon * smoothed_labels\n        # Calculate the cross-entropy loss between the model's outputs and the smoothed labels\n        if return_sl:\n            return smoothed_labels\n        \n        loss_fn = nn.CrossEntropyLoss()\n        return loss_fn(outputs, smoothed_labels)\n    \n    \nclass WSLSmoothing(nn.Module):\n    \"\"\"\n    Integrates traditional label smoothing with Weakly Supervised Label Smoothing (WSLS) \n    as described in the article. This implementation is specifically designed for binary \n    classification where label 0 is considered the negative class.\n    \"\"\"\n    def __init__(self, nb_labels=2, smoothing=0.1):\n        super().__init__()\n        self.smoothing = smoothing\n        self.ls = LSmoothing(nb_labels)\n        self.num_classes = 2\n        \n\n    def forward(self, outputs, targets, ns_scores, smoothing=0.1):\n        ns_scores = ns_scores.unsqueeze(-1)  # Ensure ns_scores is always [N, 1]\n\n        # Compute smoothed labels using the original label smoothing class\n        smoothed_labels = self.ls(outputs, targets, ns_scores, smoothing, True)\n        adjusted_labels = torch.zeros_like(smoothed_labels)\n\n        # Indices for positive and negative logits\n        pos_indices = targets == 1\n        neg_indices = targets == 0\n\n        # Adjust the positive and negative class weights using ns_scores\n        adjusted_labels[pos_indices, 1] = (1 - smoothing) + smoothing * ns_scores[pos_indices].squeeze(-1)\n        adjusted_labels[neg_indices, 0] = (1 - smoothing) * ns_scores[neg_indices].squeeze(-1) + smoothing / (self.num_classes - 1)\n        adjusted_labels[neg_indices, 1] = (1 - smoothing) * (1 - ns_scores[neg_indices].squeeze(-1)) + smoothing / (self.num_classes - 1)\n\n        # Calculate the cross-entropy loss using the adjusted labels\n             \n        loss_fn = nn.CrossEntropyLoss()\n        return loss_fn(outputs, adjusted_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\n\nclass Trainer:\n    \"\"\"A class to represent the training process for the U-Net model for vessel segmentation.\n    \"\"\"\n    def __init__(self) -> None:\n        self.model : torch.nn.Module = None\n        self.train_loader : DataLoader = None\n        self.val_loader : DataLoader = None\n        self.loss_fn : torch.nn.Module = None\n        self.optimizer : torch.optim.Optimizer = None\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.history = {\n            \"validation\": {\n                \"accuracy\": [],\n                \"loss\": [],\n                \"precision\": [],\n                \"recall\": []\n            },\n            \"training\": {\n                \"accuracy\": [],\n                \"loss\": [],\n                \"precision\": [],\n                \"recall\": []\n            },\n            \"params\": {\n                \"learning_rate\": None,\n                \"weight_decay\": None,\n                \"epochs\": None,\n                \"smoothing\" : None,\n            }\n        }\n\n    def save_model(self, path : str = \"model.pth\", history_path : str = \"history.txt\"):\n        \"\"\"Method to save the model.\n        \"\"\"\n        print(\"Saving the model...\")\n        torch.save(self.model.state_dict(), path)\n        torch.save(self.history, history_path)\n        print(\"Model saved.\")\n\n    def set_optimizer(self, optimizer : str):\n        \"\"\"Method to set the optimizer for the model.\n        @param optimizer, The optimizer to be used for training the model.\n        \"\"\"\n        self.optimizer : torch.optim.Optimizer = optimizer\n        return self\n    \n    def set_model(self, model : torch.nn.Module):\n        \"\"\"Method to set the model for training.\n        @param model, The model to be trained.\n        \"\"\"\n        self.model = model\n        return self\n    \n    def set_loader(self, train_loader : DataLoader, val_loader : DataLoader | None, test_loader : DataLoader | None):\n        \"\"\"Method to set the training and validation data loaders.\n        @param train_loader : DataLoader, The training data loader.\n        @param val_loader : DataLoader, The validation data loader.\n        @param test_loader : DataLoader, The test data loader.\n        \"\"\"\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.test_loader = test_loader\n        return self\n    \n    def set_loss_fn(self, loss_fn : torch.nn.Module):\n        \"\"\"Method to set the loss function for training the model.\n        @param loss_fn, The loss function to be used for training the model.\n        \"\"\"\n        self.loss_fn = loss_fn\n        return self\n    \n    def train(self):\n        \"\"\"Method to train the model\"\"\"\n        print(\"Training...\")\n        self.model.train()\n        train_loss = 0\n        for inputs, labels, ns_scores in self.train_loader:\n            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n            labels = labels.to(self.device)\n            ns_scores = ns_scores.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(**inputs)\n            loss = self.loss_fn(outputs, labels, ns_scores, self.smoothing)\n            loss.backward()\n            self.optimizer.step()\n            train_loss += loss.item()\n        return train_loss\n    \n    def validate(self):\n        \"\"\"Methode to validate the model\"\"\"\n        print(\"Validating...\")\n        self.model.eval()\n        with torch.no_grad():\n            val_loss = 0\n            for inputs, labels, ns_scores in self.val_loader:\n                inputs = {k: v.to(self.device) for k, v in inputs.items()}\n                labels = labels.to(self.device)\n                ns_scores = ns_scores.to(self.device)\n                outputs = self.model(**inputs)\n                loss = self.loss_fn(outputs, labels, ns_scores, self.smoothing)\n                val_loss += loss.item()\n            return val_loss\n        \n    def fit(self, learning_rate = 1e-4, epochs : int = 100, weight_decay : float = 0.01, smoothing : float = 0.1, CL=False):\n        \"\"\"Method to train the model.\n        @param learning_rate : float, The learning rate for the optimizer.\n        @param epochs : int, The number of epochs for training the model.\n        \"\"\"\n        print(f\"Training the model on {self.device}...\")\n        self.model.to(self.device)\n        self.smoothing = smoothing\n        self.optimizer = self.optimizer(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n        \n        self.history[\"params\"][\"learning_rate\"] = learning_rate\n        self.history[\"params\"][\"weight_decay\"] = weight_decay\n        self.history[\"params\"][\"epochs\"] = epochs\n        self.history[\"params\"][\"smoothing\"] = smoothing\n\n        val_loss, train_loss = [], []\n        for epoch in range(epochs):\n            train_loss_epoch = self.train()\n            if self.val_loader is not None:\n                val_loss_epoch = self.validate()\n                val_loss.append(val_loss_epoch / len(self.val_loader))\n\n            train_loss.append(train_loss_epoch/len(self.train_loader))\n\n            # for curriculum learning\n            if CL and epoch == epochs//2:\n                self.smoothing = 0.0\n\n            print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {train_loss[-1]}, Validation Loss: {val_loss[-1]}\")\n\n        print(\"Training complete.\")\n        self.history[\"training\"][\"loss\"] = train_loss\n        self.history[\"validation\"][\"loss\"] = val_loss\n\n        return self.history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/question-pairs-dataset/questions.csv'\nbs = 32\nbm25_sampling = True\n\ndata = load_data(path, 1000)\ndata['global_docno'] = data.index.astype(str)\ntrain_data, val_data, test_data = split_data(data)\nif bm25_sampling : \n    index_ref_tr = index_data(train_data,type_df=\"train_7\")\n    index_ref_val = index_data(val_data,type_df=\"val_7\")\n    index_ref_test = index_data(test_data,type_df=\"test_7\")\n    train_data = BM25Sampling.sample(index_ref_tr,train_data, k=9).sort_values(by=\"question1\")\n    val_data = BM25Sampling.sample(index_ref_val,val_data, k=9).sort_values(by=\"question1\")\n    test_data = BM25Sampling.sample(index_ref_test,test_data, k=9).sort_values(by=\"question1\")\nelse:\n    train_data = RandomSampling.sample(train_data, k=9).sort_values(by=\"question1\")\n    val_data = RandomSampling.sample(val_data, k=9).sort_values(by=\"question1\")\n    test_data = RandomSampling.sample(test_data, k=9).sort_values(by=\"question1\")\n\ntrain_dataset = QuoraDataset(train_data, tokenizer, max_length=128)\ntrain_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\nval_dataset = QuoraDataset(val_data, tokenizer, max_length=128)\nval_loader = DataLoader(val_dataset, batch_size=10, shuffle=False)\ntest_dataset = QuoraDataset(test_data, tokenizer, max_length=128)\ntest_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.shape,test_data.shape,val_data.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nepochs = 5\nlearning_rate = 1e-4\n\nmodel = BertForQuestionPairClassification()\nmodel = model.to(device)\noptimizer = torch.optim.AdamW\nloss = WSLSmoothing()\ntrainer = Trainer()\nhistory = trainer.set_model(model)\\\n    .set_loader(train_loader, val_loader, None)\\\n    .set_loss_fn(loss)\\\n    .set_optimizer(optimizer)\\\n    .fit(learning_rate, epochs, CL=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss = history['training']['loss']\nval_loss = history['validation']['loss']\n\nplt.style.use('ggplot')\nplt.figure(figsize=(15,10))\nplt.plot(train_loss, label='train loss')\nplt.plot(val_loss, label='val loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recall_at_k(all_scores, all_targets, K, num_duplicate):\n    top_k_indices = np.argsort(all_scores)[::-1][:K]\n    top_k_targets = all_targets[top_k_indices]\n    # Calculate recall\n    recall = np.sum(top_k_targets) / num_duplicate\n    return recall\n\ndef evaluate_ranking_model(model, data_loader, K, device):\n    model.eval()\n    model.to(device)\n    recalls = []\n    with torch.no_grad():\n        for inputs, labels, ns_scores in data_loader:\n            # Move all inputs to the correct device\n            inputs = {k: v.to(device) for k, v in inputs.items()}\n            labels = labels.to(device)\n            ns_scores = ns_scores.to(device)\n            outputs = model(**inputs)\n            scores = torch.softmax(outputs, dim=1)[:, 1]  # Probability of being similar\n            scores = scores.cpu().numpy()\n            targets = labels.cpu().numpy()\n            # Assume all entries in a batch belong to one group/query\n            num_duplicate = np.sum(targets)  # Count of relevant documents/questions\n            if num_duplicate == 0:\n                continue  # Avoid division by zero\n            recall_k = recall_at_k(scores, targets, K, num_duplicate)\n            recalls.append(recall_k)\n\n    # Average over all queries\n    avg_recall = np.mean(recalls)\n    return {\n        f\"recall_at_{K}\": avg_recall\n    }\n\nmetrics = evaluate_ranking_model(model, test_loader, K=1, device=device)\nprint(\"Ranking Metrics:\", metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}